airflow:
  external_sensor_default_args:
    poll_interval: 30
    timeout: 28800
    mode: reschedule
    deferrable: true
  with_data_node: false
  is_dummy_operator_short_circuit: false


neo4j:
  host: neo4j
#  port:


elastic_search:
  host: elasticsearch
#  port:
  index: index


redshift:
#  conn_id:
#  iam_role:


spark:
#  job_bucket:
#  default_queue:
#  cluster_name:
#  overhead_multiplier:


batch:
#  aws_region:
#  aws_conn_id:
#  default_queue:
#  cluster_name:

athena:
#  aws_conn_id:
#  default_s3_output_bucket:
#  default_s3_output_path:
#  s3_tmp_results_location:
#  default_workgroup:
#  default_output_format:


sqoop:
#  default_files_format: avro
#  default_properties:
#    mapreduce.job.user.classpath.first: "true"


alert:
#  slack_token:
#  default_alert:
#    type: slack
#    channel: "#airflow-jobs"
#    mentions:
