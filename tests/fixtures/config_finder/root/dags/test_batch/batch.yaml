type: batch
description: Joining data1 and data2 to calculate
inputs:
  - type: s3
    name: data1
    bucket: datalake
    path: path/{{ds}}/
outputs:
  - type: redshift
    name: batch_table
    schema: dwh
    table: batch_table
  - type: gdrive
    name: report
    folder: "1jxu_wXJa-r-m0R9JS-gOQpQIzmIoNDdL"
    file_name: report.csv
  - type: s3
    name: env_var_test_output
    bucket: cho${ENV}-test
    path: test_path
task_parameters:
    absolute_job_name: tst
    executable: batch.py
    executable_prefix: python
    job_name: batch_job
    tags:
      - sample_batch
airflow_task_parameters:
template_parameters:
  const: 13
